"""
è½»é‡çº§æ£€ç´¢å™¨ - åªè´Ÿè´£æŸ¥è¯¢ï¼Œä¸è´Ÿè´£å»ºç«‹ç´¢å¼•
"""

import os
import pickle
import json
import time
from typing import List, Dict, Any, Optional

# ChromaDBç›¸å…³
import chromadb
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.core import Settings
from llama_index.core.schema import TextNode
from llama_index.core.retrievers import VectorIndexRetriever

# BM25å’Œåˆ†è¯
from rank_bm25 import BM25Okapi
import jieba


class RAGRetriever:
    """è½»é‡çº§RAGæ£€ç´¢å™¨"""
    
    def __init__(self, data_base_path: str):
        self.data_base_path = os.path.expanduser(data_base_path)
        
        # æ•°æ®è·¯å¾„
        self.chroma_db_path = os.path.join(self.data_base_path, "chroma_db")
        self.pickle_path = os.path.join(self.data_base_path, "models")
        self.state_path = os.path.join(self.data_base_path, "state")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
        self._ensure_directories()
        
        # æ ¸å¿ƒç»„ä»¶
        self.chroma_client = None
        self.vector_store = None
        self.vector_index = None
        self.bm25_model = None
        self.nodes_data = None
        self.embed_model = None
        
        # çŠ¶æ€
        self._loaded = False
        self._last_version = None
        
    def _ensure_directories(self):
        """ç¡®ä¿æ‰€éœ€çš„ç›®å½•ç»“æ„å­˜åœ¨"""
        directories = [
            self.data_base_path,
            self.chroma_db_path,
            self.pickle_path,
            self.state_path
        ]
        
        for directory in directories:
            try:
                os.makedirs(directory, exist_ok=True)
            except OSError as e:
                # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œè®°å½•ä½†ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè®©åç»­çš„is_availableæ£€æŸ¥å¤„ç†
                pass
        
    def is_available(self) -> bool:
        """æ£€æŸ¥RAGç³»ç»Ÿæ˜¯å¦å¯ç”¨"""
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = [
            self.chroma_db_path,
            os.path.join(self.pickle_path, "bm25_model.pkl"),
            os.path.join(self.pickle_path, "nodes_data.pkl")
        ]
        
        for file_path in required_files:
            if not os.path.exists(file_path):
                return False
                
        return True
        
    def _check_version_change(self) -> bool:
        """æ£€æŸ¥æ•°æ®ç‰ˆæœ¬æ˜¯å¦æœ‰å˜åŒ–"""
        version_file = os.path.join(self.state_path, "data_version.json")
        
        try:
            if os.path.exists(version_file):
                with open(version_file, 'r', encoding='utf-8') as f:
                    version_data = json.load(f)
                    current_version = version_data.get('version')
                    
                    if current_version != self._last_version:
                        self._last_version = current_version
                        return True
        except:
            pass
            
        return False
        
    def _lazy_load(self):
        """å»¶è¿ŸåŠ è½½æ•°æ®ï¼Œåªåœ¨éœ€è¦æ—¶åŠ è½½"""
        if self._loaded and not self._check_version_change():
            return
            
        print("ğŸ”„ åŠ è½½RAGæ•°æ®...")
        
        try:
            # 1. è®¾ç½®åµŒå…¥æ¨¡å‹
            self._setup_embedding_model()
            
            # 2. åŠ è½½å‘é‡å­˜å‚¨
            self._load_vector_store()
            
            # 3. åŠ è½½BM25æ¨¡å‹
            self._load_bm25_model()
            
            self._loaded = True
            print("âœ… RAGæ•°æ®åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ RAGæ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
            
    def _setup_embedding_model(self):
        """è®¾ç½®åµŒå…¥æ¨¡å‹"""
        self.embed_model = OllamaEmbedding(
            model_name="bge-m3:latest",
            base_url="http://localhost:11434",
            embed_batch_size=8,
            request_timeout=30,
        )
        Settings.embed_model = self.embed_model
        
    def _load_vector_store(self):
        """åŠ è½½å‘é‡å­˜å‚¨å’Œç´¢å¼•"""
        self.chroma_client = chromadb.PersistentClient(path=self.chroma_db_path)
        collection_name = "rag_demo"
        chroma_collection = self.chroma_client.get_or_create_collection(name=collection_name)
        
        self.vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
        storage_context = StorageContext.from_defaults(vector_store=self.vector_store)
        
        self.vector_index = VectorStoreIndex.from_vector_store(
            self.vector_store,
            storage_context=storage_context,
            embed_model=self.embed_model
        )
        
    def _load_bm25_model(self):
        """åŠ è½½BM25æ¨¡å‹å’ŒèŠ‚ç‚¹æ•°æ®"""
        bm25_file = os.path.join(self.pickle_path, "bm25_model.pkl")
        nodes_file = os.path.join(self.pickle_path, "nodes_data.pkl")
        
        with open(bm25_file, 'rb') as f:
            self.bm25_model = pickle.load(f)
            
        with open(nodes_file, 'rb') as f:
            nodes_data = pickle.load(f)
            
        # é‡å»ºèŠ‚ç‚¹å¯¹è±¡
        self.nodes_data = []
        for node_data in nodes_data:
            node = TextNode(
                text=node_data['text'],
                metadata=node_data['metadata'],
                id_=node_data['node_id']
            )
            self.nodes_data.append(node)
            
    def search(self, query: str, top_k: int = 9) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ··åˆæ£€ç´¢ - ä¸rag_demo.pyçš„æ£€ç´¢é€»è¾‘ä¿æŒä¸€è‡´"""
        if not self.is_available():
            return []
            
        self._lazy_load()
        
        if not self._loaded:
            return []
            
        try:
            # åˆ›å»ºæ··åˆæ£€ç´¢å™¨ - å‚è€ƒrag_demo.pyçš„create_hybrid_retrieveræ–¹æ³•
            retriever = self._create_hybrid_retriever(similarity_top_k=top_k * 2)
            
            # æ‰§è¡Œæ··åˆæ£€ç´¢
            nodes = retriever.retrieve(query)
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for node in nodes:
                # è·å–æ–‡ä»¶è·¯å¾„
                file_path = node.metadata.get('file_path', 'æœªçŸ¥è·¯å¾„')
                filename = os.path.basename(file_path) if file_path != 'æœªçŸ¥è·¯å¾„' else 'æœªçŸ¥æ–‡ä»¶'
                
                # è·å–åˆ†æ•°ï¼šä¼˜å…ˆä»metadataè·å–æ··åˆåˆ†æ•°ï¼Œå¦åˆ™ä½¿ç”¨èŠ‚ç‚¹åŸæœ‰åˆ†æ•°
                score = 0.0
                if hasattr(node, 'metadata') and node.metadata and 'hybrid_score' in node.metadata:
                    score = node.metadata['hybrid_score']
                    retrieval_source = node.metadata.get('retrieval_source', 'hybrid')
                else:
                    score = getattr(node, 'score', 0.0)
                    retrieval_source = 'vector'
                
                # ç¡®ä¿scoreæ˜¯æµ®ç‚¹æ•°
                try:
                    score = float(score) if score is not None else 0.0
                    if score < 0:
                        score = 0.0
                except (ValueError, TypeError):
                    score = 0.0
                
                formatted_results.append({
                    'rank': len(formatted_results) + 1,
                    'content': node.text.strip(),
                    'score': score,
                    'file_path': file_path,
                    'filename': filename,
                    'content_length': len(node.text),
                    'retrieval_source': retrieval_source
                })
            
            # æŒ‰ç›¸ä¼¼åº¦å¾—åˆ†æ’åºå¹¶é™åˆ¶è¿”å›æ•°é‡
            formatted_results.sort(key=lambda x: x['score'], reverse=True)
            formatted_results = formatted_results[:top_k]
            
            # é‡æ–°åˆ†é…æ’å
            for i, result in enumerate(formatted_results):
                result['rank'] = i + 1
                
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
            
    def _bm25_search(self, query: str, top_k: int) -> List[tuple]:
        """BM25æ£€ç´¢"""
        if not self.bm25_model or not self.nodes_data:
            return []
            
        # å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†è¯
        tokenized_query = list(jieba.cut(query, cut_all=False))
        
        # BM25æ£€ç´¢
        scores = self.bm25_model.get_scores(tokenized_query)
        
        # è·å–top_kç»“æœ
        top_indices = scores.argsort()[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            if idx < len(self.nodes_data):
                node = self.nodes_data[idx]
                score = float(scores[idx])
                results.append((node, score, 'bm25'))
                
        return results
        
    def _fuse_results(self, vector_results, bm25_results, top_k: int) -> List[tuple]:
        """èåˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢ç»“æœ"""
        all_results = {}
        
        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        for i, node in enumerate(vector_results):
            node_key = hash(node.text[:200])
            rrf_score = 1.0 / (i + 1)  # å€’æ•°æ’åèåˆ
            all_results[node_key] = {
                'node': node,
                'score': rrf_score,
                'source': 'vector'
            }
            
        # å¤„ç†BM25æ£€ç´¢ç»“æœ
        for i, (node, bm25_score, source) in enumerate(bm25_results):
            node_key = hash(node.text[:200])
            rrf_score = 1.0 / (i + 1)
            
            if node_key in all_results:
                # åˆå¹¶åˆ†æ•°
                all_results[node_key]['score'] += rrf_score
                all_results[node_key]['source'] = 'hybrid'
            else:
                all_results[node_key] = {
                    'node': node,
                    'score': rrf_score,
                    'source': 'bm25'
                }
                
        # æŒ‰èåˆåˆ†æ•°æ’åº
        sorted_results = sorted(all_results.values(), 
                              key=lambda x: x['score'], reverse=True)
        
        # è½¬æ¢ä¸ºè¿”å›æ ¼å¼
        final_results = []
        for result in sorted_results[:top_k]:
            final_results.append((
                result['node'], 
                result['score'], 
                result['source']
            ))
            
        return final_results
            
    def _create_hybrid_retriever(self, similarity_top_k: int = 10):
        """åˆ›å»ºæ··åˆæ£€ç´¢å™¨ - ä¸rag_demo.pyçš„create_hybrid_retrieveræ–¹æ³•ä¿æŒä¸€è‡´"""
        try:
            
            # 1. åˆ›å»ºå‘é‡æ£€ç´¢å™¨
            vector_retriever = VectorIndexRetriever(
                index=self.vector_index,
                similarity_top_k=similarity_top_k,
            )
            
            # 2. åˆ›å»ºBM25æ£€ç´¢å™¨ï¼ˆéœ€è¦æ‰€æœ‰èŠ‚ç‚¹ï¼‰
            if not self.nodes_data:
                print("âš ï¸ æ²¡æœ‰èŠ‚ç‚¹å¯ç”¨äºBM25æ£€ç´¢ï¼Œä»…ä½¿ç”¨å‘é‡æ£€ç´¢")
                return vector_retriever
                
            # å‡†å¤‡BM25è¯­æ–™åº“ï¼ˆä¸­æ–‡åˆ†è¯ï¼‰
            tokenized_corpus = []
            for node in self.nodes_data:
                # ä¸­æ–‡åˆ†è¯
                tokens = list(jieba.cut(node.text, cut_all=False))
                tokenized_corpus.append(tokens)
            
            # åˆ›å»ºBM25æ¨¡å‹
            bm25 = BM25Okapi(tokenized_corpus)
            
            # åˆ›å»ºè‡ªå®šä¹‰BM25æ£€ç´¢å™¨
            class CustomBM25Retriever:
                def __init__(self, bm25_model, nodes, similarity_top_k=10):
                    self.bm25 = bm25_model
                    self.nodes = nodes
                    self.similarity_top_k = similarity_top_k
                
                def retrieve(self, query_str):
                    # å¯¹æŸ¥è¯¢è¿›è¡Œåˆ†è¯
                    tokenized_query = list(jieba.cut(query_str, cut_all=False))
                    
                    # BM25æ£€ç´¢
                    scores = self.bm25.get_scores(tokenized_query)
                    
                    # è·å–top_kç»“æœ
                    top_indices = scores.argsort()[-self.similarity_top_k:][::-1]
                    
                    # è¿”å›èŠ‚ç‚¹å’Œåˆ†æ•°ä¿¡æ¯
                    results = []
                    for idx in top_indices:
                        if idx < len(self.nodes):
                            node = self.nodes[idx]
                            results.append((node, float(scores[idx])))
                    
                    return results
            
            bm25_retriever = CustomBM25Retriever(bm25, self.nodes_data, similarity_top_k)
            
            # 3. åˆ›å»ºç®€åŒ–çš„æ··åˆæ£€ç´¢å™¨
            class SimpleHybridRetriever:
                def __init__(self, vector_retriever, bm25_retriever, similarity_top_k=10):
                    self.vector_retriever = vector_retriever
                    self.bm25_retriever = bm25_retriever
                    self.similarity_top_k = similarity_top_k
                
                def retrieve(self, query_str):
                    # æ‰§è¡Œå‘é‡æ£€ç´¢
                    vector_results = self.vector_retriever.retrieve(query_str)
                    
                    # æ‰§è¡ŒBM25æ£€ç´¢ï¼ˆè¿”å›(node, score)å…ƒç»„ï¼‰
                    bm25_results = self.bm25_retriever.retrieve(query_str)
                    
                    # åˆå¹¶ç»“æœï¼ˆç®€å•RRFèåˆï¼‰
                    all_results = {}
                    
                    # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ - ä½¿ç”¨æ–‡æœ¬å†…å®¹ä½œä¸ºå”¯ä¸€æ ‡è¯†
                    for i, node in enumerate(vector_results):
                        # ä½¿ç”¨æ–‡æœ¬å†…å®¹çš„å“ˆå¸Œå€¼ä½œä¸ºå”¯ä¸€æ ‡è¯†
                        node_key = hash(node.text[:200])
                        rrf_score = 1.0 / (i + 1)  # å€’æ•°æ’åèåˆ
                        all_results[node_key] = {
                            'node': node,
                            'score': rrf_score,
                            'source': 'vector'
                        }
                    
                    # å¤„ç†BM25æ£€ç´¢ç»“æœï¼ˆå¤„ç†(node, score)å…ƒç»„æ ¼å¼ï¼‰
                    for i, item in enumerate(bm25_results):
                        if isinstance(item, tuple):
                            node, bm25_score = item
                        else:
                            node = item
                            bm25_score = 0.0
                            
                        # ä½¿ç”¨ç›¸åŒçš„èŠ‚ç‚¹æ ‡è¯†æ–¹æ³•
                        node_key = hash(node.text[:200])
                        rrf_score = 1.0 / (i + 1)
                        
                        if node_key in all_results:
                            # åˆå¹¶åˆ†æ•° - è¿™é‡Œæ‰æ˜¯çœŸæ­£çš„æ··åˆæ£€ç´¢
                            all_results[node_key]['score'] += rrf_score
                            all_results[node_key]['source'] = 'hybrid'
                        else:
                            all_results[node_key] = {
                                'node': node,
                                'score': rrf_score,
                                'source': 'bm25'
                            }
                    
                    # æŒ‰èåˆåˆ†æ•°æ’åº
                    sorted_results = sorted(all_results.values(), 
                                          key=lambda x: x['score'], reverse=True)
                    
                    # è¿”å›å¸¦æœ‰ä¸´æ—¶åˆ†æ•°ä¿¡æ¯çš„èŠ‚ç‚¹åˆ—è¡¨
                    final_results = []
                    for result in sorted_results[:self.similarity_top_k]:
                        node = result['node']
                        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ç»“æœå¯¹è±¡ï¼ŒåŒ…å«èŠ‚ç‚¹å’Œåˆ†æ•°ä¿¡æ¯
                        class NodeWithScore:
                            def __init__(self, node, score, source):
                                self.text = node.text
                                self.metadata = node.metadata.copy() if node.metadata else {}
                                self.metadata['hybrid_score'] = score
                                self.metadata['retrieval_source'] = source
                        
                        result_node = NodeWithScore(node, result['score'], result['source'])
                        final_results.append(result_node)
                    
                    return final_results
            
            hybrid_retriever = SimpleHybridRetriever(vector_retriever, bm25_retriever, similarity_top_k)
            return hybrid_retriever
            
        except Exception as e:
            print(f"âš ï¸ æ··åˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨å‘é‡æ£€ç´¢: {str(e)}")
            return VectorIndexRetriever(index=self.vector_index, similarity_top_k=similarity_top_k)